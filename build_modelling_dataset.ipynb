{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d16da3-b27e-4210-a1de-583212ae4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_modelling_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e22d707-7569-4f99-8e4b-3d4a23ec1748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ modelling_dataset.csv (851499, 28)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# static features\n",
    "static = pd.read_csv(\"feature_static_london.csv\")\n",
    "\n",
    "# dynamic crime features\n",
    "crime_dyn = pd.read_csv(\"crime_rolling6m.csv\")\n",
    "\n",
    "# merge\n",
    "panel = (\n",
    "    crime_dyn.merge(static, on=\"LSOA_Code\", how=\"left\")\n",
    "             .dropna()   # ensure no missing\n",
    ")\n",
    "\n",
    "panel.to_csv(\"modelling_dataset.csv\", index=False)\n",
    "print(\"✓ modelling_dataset.csv\", panel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d087894-7048-4241-aca9-aef88cca10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ columns renamed and saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "imd = pd.read_csv(\"imd_london.csv\")\n",
    "\n",
    "rename_map = {\n",
    "    \"income_pct\":     \"dep_income\",\n",
    "    \"employment_pct\": \"dep_employment\",\n",
    "    \"education_pct\":  \"dep_education\",\n",
    "    \"health_pct\":     \"dep_health\",\n",
    "    \"barriers_pct\":   \"dep_barriers\",\n",
    "    \"livingenv_pct\":  \"dep_livingenv\",\n",
    "}\n",
    "\n",
    "imd = imd.rename(columns=rename_map)\n",
    "\n",
    "imd.to_csv(\"imd_london.csv\", index=False)\n",
    "print(\"✓ columns renamed and saved\")\n",
    "panel = pd.read_csv(\"modelling_dataset.csv\")\n",
    "\n",
    "panel = panel.rename(columns=rename_map)\n",
    "panel.to_csv(\"modelling_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0fe3a8-6291-414d-8625-9f9b74a5e771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (851499, 33)\n",
      "missing values: 0\n",
      "✓ saved modelling_dataset_ready.csv (851499, 35)\n",
      "date range: 2010-04-01 00:00:00 → 2025-06-01 00:00:00\n",
      "positive class share (y_cls=1): 0.248\n"
     ]
    }
   ],
   "source": [
    "# build_modelling_dataset_ready.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CRIME_FILE  = \"crime_rolling6m.csv\"\n",
    "STATIC_FILE = \"feature_static_london.csv\"\n",
    "\n",
    "# 1| load\n",
    "crime  = pd.read_csv(CRIME_FILE, parse_dates=[\"date\"], dtype={\"LSOA_Code\":\"string\"})\n",
    "static = pd.read_csv(STATIC_FILE, dtype={\"LSOA_Code\":\"string\"})\n",
    "\n",
    "# 2| identify crime category columns and total\n",
    "if CRIME_FILE.endswith(\"crime_rolling6m.csv\"):\n",
    "    cat_cols = [c for c in crime.columns if c.startswith(\"cnt_\") and c.endswith(\"_roll6\")]\n",
    "else:\n",
    "    cat_cols = [c for c in crime.columns if c.startswith(\"cnt_\") and not c.endswith(\"_roll6\")]\n",
    "\n",
    "crime[\"cnt_total\"] = crime[cat_cols].sum(axis=1)\n",
    "\n",
    "# 3| time features\n",
    "crime[\"year\"]  = crime[\"date\"].dt.year\n",
    "crime[\"month\"] = crime[\"date\"].dt.month\n",
    "crime[\"sin_m\"] = np.sin(2*np.pi*crime[\"month\"]/12.0)\n",
    "crime[\"cos_m\"] = np.cos(2*np.pi*crime[\"month\"]/12.0)\n",
    "\n",
    "# add a simple 1-month lag only for monthly snapshot table\n",
    "if CRIME_FILE.endswith(\"crime_monthly_wide.csv\"):\n",
    "    crime = crime.sort_values([\"LSOA_Code\",\"date\"])\n",
    "    crime[\"cnt_total_lag1\"] = crime.groupby(\"LSOA_Code\")[\"cnt_total\"].shift(1).fillna(0)\n",
    "\n",
    "# 4| merge with static\n",
    "panel = crime.merge(static, on=\"LSOA_Code\", how=\"left\")\n",
    "\n",
    "# sanity checks\n",
    "print(\"shape:\", panel.shape)\n",
    "print(\"missing values:\", panel.isna().sum().sum())\n",
    "\n",
    "# 5| targets\n",
    "panel[\"y_reg\"] = panel[\"cnt_total\"]\n",
    "thr = panel[\"cnt_total\"].quantile(0.75)\n",
    "panel[\"y_cls\"] = (panel[\"cnt_total\"] > thr).astype(int)\n",
    "\n",
    "# 6| save\n",
    "panel.to_csv(\"modelling_dataset_ready.csv\", index=False)\n",
    "print(\"✓ saved modelling_dataset_ready.csv\", panel.shape)\n",
    "print(\"date range:\", panel[\"date\"].min(), \"→\", panel[\"date\"].max())\n",
    "print(\"positive class share (y_cls=1):\", round(panel[\"y_cls\"].mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935a422f-e25b-4562-ae61-cc37decd36a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: (842193, 33) → modelling_dataset_no_leak.csv\n",
      "Logistic AUC: 0.915\n",
      "RF AUC: 0.917\n"
     ]
    }
   ],
   "source": [
    "# Build a leakage-free panel:\n",
    "#   X: lagged (t-1) rolling-6m features + seasonality + static\n",
    "#   y: next-month (t+1) total count & high-risk flag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROLL6   = \"crime_rolling6m.csv\"\n",
    "MONTHLY = \"crime_monthly_wide.csv\"\n",
    "STATIC  = \"feature_static_london.csv\"\n",
    "\n",
    "# 1| FEATURES: rolling-6m at t-1 (lagged)\n",
    "feat = pd.read_csv(ROLL6, parse_dates=[\"date\"], dtype={\"LSOA_Code\":\"string\"}).sort_values([\"LSOA_Code\",\"date\"])\n",
    "roll_cols = [c for c in feat.columns if c.startswith(\"cnt_\") and c.endswith(\"_roll6\")]\n",
    "\n",
    "# create 1-lag versions so that X_t only uses info up to t-1\n",
    "for c in roll_cols:\n",
    "    feat[f\"{c}_lag1\"] = feat.groupby(\"LSOA_Code\")[c].shift(1)\n",
    "\n",
    "# keep only lagged columns to be safe\n",
    "lag_cols = [f\"{c}_lag1\" for c in roll_cols]\n",
    "feat = feat[[\"LSOA_Code\",\"date\"] + lag_cols].dropna()\n",
    "\n",
    "# seasonality\n",
    "feat[\"month\"] = feat[\"date\"].dt.month\n",
    "feat[\"sin_m\"] = np.sin(2*np.pi*feat[\"month\"]/12.0)\n",
    "feat[\"cos_m\"] = np.cos(2*np.pi*feat[\"month\"]/12.0)\n",
    "\n",
    "# 2| TARGETS: next-month totals (t+1) from monthly-wide\n",
    "mon = pd.read_csv(MONTHLY, parse_dates=[\"date\"], dtype={\"LSOA_Code\":\"string\"})\n",
    "mon_cols = [c for c in mon.columns if c.startswith(\"cnt_\") and not c.endswith(\"_roll6\")]\n",
    "mon[\"cnt_total\"] = mon[mon_cols].sum(axis=1)\n",
    "\n",
    "# y_next aligns with features at time t\n",
    "mon[\"y_next\"] = mon.groupby(\"LSOA_Code\")[\"cnt_total\"].shift(-1)\n",
    "target = mon[[\"LSOA_Code\",\"date\",\"y_next\"]].dropna()\n",
    "\n",
    "# 3| MERGE: X (lagged roll6) + static + y_next\n",
    "static = pd.read_csv(STATIC, dtype={\"LSOA_Code\":\"string\"})\n",
    "df = (feat.merge(static, on=\"LSOA_Code\", how=\"left\")\n",
    "          .merge(target, on=[\"LSOA_Code\",\"date\"], how=\"inner\"))\n",
    "\n",
    "# classification target (global 75% threshold on y_next)\n",
    "thr = df[\"y_next\"].quantile(0.75)\n",
    "df[\"y_cls\"] = (df[\"y_next\"] > thr).astype(int)\n",
    "\n",
    "# remove ID/time cols from X later; save dataset\n",
    "df.to_csv(\"modelling_dataset_no_leak.csv\", index=False)\n",
    "print(\"Saved:\", df.shape, \"→ modelling_dataset_no_leak.csv\")\n",
    "\n",
    "# 4| BASELINES (classification)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# time-based split\n",
    "train = df[df[\"date\"] < \"2020-01-01\"]\n",
    "test  = df[df[\"date\"] >= \"2020-01-01\"]\n",
    "\n",
    "drop_cols = [\"LSOA_Code\",\"date\",\"y_next\",\"y_cls\"]\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[\"y_cls\"]\n",
    "X_test  = test.drop(columns=drop_cols)\n",
    "y_test  = test[\"y_cls\"]\n",
    "\n",
    "# Logistic Regression (no strict need to scale tree-friendly features)\n",
    "logit = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "logit.fit(X_train, y_train)\n",
    "print(\"Logistic AUC:\", round(roc_auc_score(y_test, logit.predict_proba(X_test)[:,1]), 3))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"RF AUC:\", round(roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f8006-125a-4bfc-a647-c508ed1428c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nda)",
   "language": "python",
   "name": "nda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
